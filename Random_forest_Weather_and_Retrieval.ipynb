{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi6grOMXEcgO",
        "outputId": "cef48c7b-623e-48d7-9587-c1868d60b906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Starting package installation...\n",
            "DEBUG: Installation complete.\n"
          ]
        }
      ],
      "source": [
        "# --- Installations ---\n",
        "# Installing all the libraries required\n",
        "print(\"DEBUG: Starting package installation...\")\n",
        "#!pip install -q google-generativeai scikit-learn pandas gradio\n",
        "!pip install -q groq scikit-learn pandas gradio\n",
        "print(\"DEBUG: Installation complete.\")\n",
        "# ----------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Core Imports and Global Model Setup ---\n",
        "print(\"\\nDEBUG: Starting core imports...\")\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import gradio as gr\n",
        "#import google.generativeai as genai\n",
        "from groq import Groq\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "print(\"DEBUG: Imports complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q07F0r2eEinf",
        "outputId": "ae00dcdc-e70c-4e0f-e5ed-a2cf1ef95b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Starting core imports...\n",
            "DEBUG: Imports complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# --- Model Training Section ---\n",
        "print(\"\\nDEBUG: Attempting to load and train model...\")\n",
        "model = None # Initialize model globally\n",
        "try:\n",
        "    # 1. Data Loading and Preprocessing\n",
        "    df = pd.read_csv('data.csv')\n",
        "    print(f\"DEBUG: 'data.csv' loaded successfully. Shape: {df.shape}\")\n",
        "    df.columns = df.columns.str.replace(' ', '_')\n",
        "    df['ActualTemp'] = (df['Temp_Max'] + df['Temp_Min']) / 2\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "    df['day_of_year'] = df['Date'].dt.dayofyear\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    print(\"DEBUG: Feature engineering complete (ActualTemp, Date components).\")\n",
        "\n",
        "    # 2. Feature and Target Setup\n",
        "    features = ['day_of_year', 'month', 'year']\n",
        "    target = 'ActualTemp'\n",
        "    X = df[features]\n",
        "    y = df[target]\n",
        "\n",
        "    # 3. Training and Evaluation\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"DEBUG: Data split into {len(X_train)} training and {len(X_test)} testing samples.\")\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    print(f\"DEBUG: Model training complete.\")\n",
        "    print(f\"‚úÖ Model trained successfully on your CSV!\")\n",
        "    print(f\"Model Mean Absolute Error: {mae:.2f}¬∞C\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: 'data.csv' not found. Please make sure you have uploaded the file.\")\n",
        "    model = None\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred during training: {e}\")\n",
        "    model = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G63uMeGYEmpq",
        "outputId": "41f6a0b3-1988-48f2-e176-49d82ce3f017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Attempting to load and train model...\n",
            "DEBUG: 'data.csv' loaded successfully. Shape: (25500, 5)\n",
            "DEBUG: Feature engineering complete (ActualTemp, Date components).\n",
            "DEBUG: Data split into 20400 training and 5100 testing samples.\n",
            "DEBUG: Model training complete.\n",
            "‚úÖ Model trained successfully on your CSV!\n",
            "Model Mean Absolute Error: 1.08¬∞C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# --- Gemini API Configuration ---\n",
        "#API_KEY = \"AIzaSyCa_UvTrKIugk3epq-dWWPNcpqoEqd23sw\" # Replace with your actual key\n",
        "#print(\"\\nDEBUG: Configuring Gemini API client.\")\n",
        "#try:\n",
        " #   genai.configure(api_key=API_KEY)\n",
        " #   llm = genai.GenerativeModel('gemini-1.5-flash')\n",
        " #   print(\"DEBUG: Gemini client initialized successfully.\")\n",
        "#except Exception as e:\n",
        "#    print(f\"‚ùå Error initializing Gemini: {e}\")"
      ],
      "metadata": {
        "id": "el87YdkYEpd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"Your Groq Api Key\"\n",
        "print(\"\\nDEBUG: Configuring Groq API client.\")\n",
        "try:\n",
        "    groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "    print(\"DEBUG: Groq client initialized successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Groq: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1uWxClPcr3M",
        "outputId": "f54771d0-9429-4e84-fba1-e51ee9793a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Configuring Groq API client.\n",
            "DEBUG: Groq client initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Core Prediction Function with Streaming ---\n",
        "\n",
        "def predict_weather_for_date(target_date_str):\n",
        "    \"\"\"\n",
        "    Predicts temperature for a date string and streams LLM interpretation.\n",
        "    \"\"\"\n",
        "    print(\"\\nDEBUG: Function predict_weather_for_date started...\")\n",
        "\n",
        "    # 1. Input Parsing and Error Handling\n",
        "    try:\n",
        "        target_date = datetime.strptime(target_date_str, '%Y-%m-%d')\n",
        "        print(f\"DEBUG: Input string '{target_date_str}' successfully parsed to datetime object: {target_date.strftime('%Y-%m-%d')}\")\n",
        "    except ValueError:\n",
        "        error_msg = f\"Error: Date format is invalid. Please use YYYY-MM-DD (e.g., 2025-06-15).\"\n",
        "        print(f\"‚ùå DEBUG: {error_msg}\")\n",
        "        yield error_msg, \"Invalid date format provided.\"\n",
        "        return\n",
        "\n",
        "    if model is None:\n",
        "        error_msg = \"Model not trained. Please upload 'data.csv' and run the code.\"\n",
        "        print(f\"‚ùå DEBUG: {error_msg}\")\n",
        "        yield error_msg, \"Cannot provide advice. The prediction model failed to load.\"\n",
        "        return\n",
        "\n",
        "    # 2. Feature Extraction\n",
        "    day_of_year = target_date.timetuple().tm_yday\n",
        "    month = target_date.month\n",
        "    year = target_date.year\n",
        "    input_data = np.array([[day_of_year, month, year]])\n",
        "    print(f\"DEBUG: Extracted features (DoY, Month, Year): {input_data}\")\n",
        "\n",
        "    # 3. Model Prediction\n",
        "    predicted_temp = model.predict(input_data)[0]\n",
        "    print(f\"DEBUG: Prediction successful: {predicted_temp:.2f}¬∞C\")\n",
        "    prediction_text = f\"Predicted Average Temperature for {target_date.strftime('%Y-%m-%d')}: {predicted_temp:.2f}¬∞C\"\n",
        "\n",
        "    # Yield the numerical prediction immediately\n",
        "    yield prediction_text, \"Thinking...\"\n",
        "\n",
        "    # 4. Groq Interpretation with Streaming\n",
        "    print(\"DEBUG: Generating Groq interpretation with streaming...\")\n",
        "\n",
        "    # üí° ENHANCED PROMPT TEMPLATE\n",
        "    # We now provide more context and ask for a structured response\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional weather and travel advisor for Hyderabad, India.\n",
        "    Your task is to provide a concise and helpful weather summary based on the following information.\n",
        "\n",
        "    Predicted Average Temperature: {predicted_temp:.2f}¬∞C\n",
        "    Date: {target_date.strftime('%Y-%m-%d')}\n",
        "    Location: Hyderabad, India\n",
        "\n",
        "    Please provide your response in a clear and organized format, including the following sections:\n",
        "\n",
        "    **What to Wear:** Provide one to two specific clothing recommendations.\n",
        "    **Outdoor Activities:** Suggest one to two outdoor activities suitable for the weather.\n",
        "    **General Tip:** Provide a final, brief piece of advice (e.g., related to sun safety or hydration).\n",
        "\n",
        "    Keep the tone friendly and professional.\n",
        "    \"\"\"\n",
        "\n",
        "    full_interpretation = \"\"\n",
        "    try:\n",
        "        stream = groq_client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            stream=True\n",
        "        )\n",
        "\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content:\n",
        "                full_interpretation += chunk.choices[0].delta.content\n",
        "                yield prediction_text, full_interpretation\n",
        "    except Exception as e:\n",
        "        yield prediction_text, f\"Could not get friendly advice from Groq (API Error). Error: {e}\"\n",
        "        print(f\"‚ùå DEBUG: Groq API call failed: {e}\")\n",
        "\n",
        "    print(\"DEBUG: Function finished.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJX_pAwlEsnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ----------------------------------------------------\n",
        "# # --- Core Prediction Function with Streaming ---\n",
        "\n",
        "# def predict_weather_for_date(target_date_str):\n",
        "#     \"\"\"\n",
        "#     Predicts temperature for a date string and streams LLM interpretation.\n",
        "#     \"\"\"\n",
        "#     print(\"\\nDEBUG: Function predict_weather_for_date started...\")\n",
        "\n",
        "#     # 1. Input Parsing and Error Handling\n",
        "#     try:\n",
        "#         target_date = datetime.strptime(target_date_str, '%Y-%m-%d')\n",
        "#         print(f\"DEBUG: Input string '{target_date_str}' successfully parsed to datetime object: {target_date.strftime('%Y-%m-%d')}\")\n",
        "#     except ValueError:\n",
        "#         error_msg = f\"Error: Date format is invalid. Please use YYYY-MM-DD (e.g., 2025-06-15).\"\n",
        "#         print(f\"‚ùå DEBUG: {error_msg}\")\n",
        "#         # Return two-element tuple for Gradio outputs\n",
        "#         yield error_msg, \"Invalid date format provided.\"\n",
        "#         return\n",
        "\n",
        "#     if model is None:\n",
        "#         error_msg = \"Model not trained. Please upload 'data.csv' and run the code.\"\n",
        "#         print(f\"‚ùå DEBUG: {error_msg}\")\n",
        "#         yield error_msg, \"Cannot provide advice. The prediction model failed to load.\"\n",
        "#         return\n",
        "\n",
        "#     # 2. Feature Extraction\n",
        "#     day_of_year = target_date.timetuple().tm_yday\n",
        "#     month = target_date.month\n",
        "#     year = target_date.year\n",
        "#     input_data = np.array([[day_of_year, month, year]])\n",
        "#     print(f\"DEBUG: Extracted features (DoY, Month, Year): {input_data}\")\n",
        "\n",
        "#     # 3. Model Prediction\n",
        "#     predicted_temp = model.predict(input_data)[0]\n",
        "#     print(f\"DEBUG: Prediction successful: {predicted_temp:.2f}¬∞C\")\n",
        "#     prediction_text = f\"Predicted Average Temperature for {target_date.strftime('%Y-%m-%d')}: {predicted_temp:.2f}¬∞C\"\n",
        "\n",
        "#     # Yield the numerical prediction immediately\n",
        "#     yield prediction_text, \"Thinking...\"\n",
        "\n",
        "#     # 4. Gemini Interpretation with Streaming\n",
        "#     print(\"DEBUG: Generating Gemini interpretation with streaming...\")\n",
        "#     prompt = f\"\"\"\n",
        "#     The predicted average temperature is {predicted_temp:.2f}¬∞C for the date {target_date.strftime('%Y-%m-%d')}.\n",
        "#     As a friendly weather assistant, provide a concise, single-paragraph advice based on this prediction.\n",
        "#     Focus on what to wear or what activities are appropriate.\n",
        "#     \"\"\"\n",
        "\n",
        "#     full_interpretation = \"\"\n",
        "#     try:\n",
        "#         # Use stream=True to get a response as a generator\n",
        "#         for chunk in llm.generate_content(prompt, stream=True):\n",
        "#             if chunk.text:\n",
        "#                 full_interpretation += chunk.text\n",
        "#                 yield prediction_text, full_interpretation\n",
        "#     except Exception as e:\n",
        "#         yield prediction_text, f\"Could not get friendly advice from Gemini (API Error). Error: {e}\"\n",
        "#         print(f\"‚ùå DEBUG: Gemini API call failed: {e}\")\n",
        "\n",
        "#     print(\"DEBUG: Function finished.\")\n"
      ],
      "metadata": {
        "id": "RsOaYBDedjl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------------------\n",
        "# --- Gradio Interface Launch ---\n",
        "print(\"\\nDEBUG: Preparing Gradio interface...\")\n",
        "iface = gr.Interface(\n",
        "    fn=predict_weather_for_date,\n",
        "    inputs=[gr.Textbox(label=\"Select a Date to Predict\", placeholder=\"Enter date as YYYY-MM-DD (e.g., 2025-06-15)\")],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Numerical Prediction\"),\n",
        "        gr.Textbox(label=\"Friendly Advice from Groq\")\n",
        "    ],\n",
        "    title=\"üìÖ Date-Based Weather Forecaster (Random Forest with Groq)\",\n",
        "    description=\"Pick a date to forecast the temperature. Requires 'data.csv' for training.\"\n",
        ")\n",
        "\n",
        "print(\"DEBUG: Launching Gradio interface...\")\n",
        "iface.queue().launch(share=True)\n",
        "print(\"DEBUG: Gradio launch call initiated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "8Dt6-aOjE2oL",
        "outputId": "0847e213-537e-436e-ed6e-ddffe9f4d2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Preparing Gradio interface...\n",
            "DEBUG: Launching Gradio interface...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ef5518abdcd9c2622e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ef5518abdcd9c2622e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Gradio launch call initiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3LlX60dJM6d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}